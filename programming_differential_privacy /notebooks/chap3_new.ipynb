{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCRX40gQpv/+3PlC8btI2L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreavitaletti/colab/blob/main/programming_differential_privacy%20/notebooks/chap3_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PCqptjmmnyP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Counting unique users\n",
        "\n",
        "Suppose you have a database, and you want to publish how many people in there satisfy a given condition. Say, how many have green eyes? Even if you have many people in your database, you can't just publish the true answer. Let's take a moment to understand why.\n",
        "\n",
        "With differential privacy, we assume that the attacker knows almost all elements. They only have uncertainty about their target. Say they want to know whether their target has green eyes. If you output the real number k\n",
        ", they can compare it with the number of people with green eyes among the people they know. If it's k−1\n",
        ", then the target has green eyes. If it's k\n",
        ", then the target does not.\n",
        "\n",
        "So, what do we do? We compute the exact answer, and we add noise. This noise will come from a probability distribution called the Laplace distribution. This distribution has a parameter, its scale, which determines how \"flat\" it is. It looks like this:\n",
        "\n",
        "Graph showing a Laplace distribution with scale 1/ln(3), centered on 0\n",
        "So, to get ε\n",
        "-differential privacy, we pick a random value according to Laplace(1/ε)\n",
        ", and we add this noise to the real value. Why does it work? Let's look at the distribution of the number we return, depending on whether the true count is k=1000\n",
        " (blue line, the target doesn't have green eyes) or k=1001\n",
        " (yellow line, the target has green eyes).\n",
        "\n",
        "Graph showing two Laplace distributions with scale 1/ln(3), centered on 1000 and 1001\n",
        "Let's say the real number is k=1001\n",
        ", and after adding noise, we published 1003\n",
        ". Let's put ourselves in the attacker's shoes. What's the likelihood that the original number was 1001\n",
        " vs. 1000\n",
        "? The hypothesis \"k=1001\n",
        "\" is a bit more likely: generating a noise of 2\n",
        " is more likely than a noise of 3\n",
        ". How much more likely? It turns out that the ratio between these likelihoods is… eε\n",
        "! So the ratio of probabilities of differential privacy is satisfied.\n",
        "\n",
        "This works no matter what the output is: the ratio will always be between eε\n",
        " and e−ε\n",
        ". If you want to double-check, you can either verify it on the graph, or do the math."
      ],
      "metadata": {
        "id": "4-nHox2-mqVP"
      }
    }
  ]
}